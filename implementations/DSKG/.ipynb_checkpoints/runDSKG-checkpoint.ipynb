{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from reader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = Options()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "use_jeval = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## readme\n",
    "#### 1. unpack data.tar.gz\n",
    "#### 2. select a model of followings to build (FB15K-237, FB15K, and WN18)\n",
    "#### 3. run codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '237-dskg-hs512'\n",
    "\n",
    "opts.data_path = 'data/FB15k-237/'\n",
    "\n",
    "opts.hidden_size = 512\n",
    "opts.num_samples = 2048*3\n",
    "opts.keep_prob = 0.5\n",
    "opts.num_layers = 2\n",
    "opts.learning_rate=0.001\n",
    "\n",
    "model = FBRespective(opts, sess)\n",
    "# model.saver.restore(save_path='ckpt/237-dskg-hs512_4', sess= sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'fb-dskg-hs512'\n",
    "\n",
    "opts.hidden_size = 512\n",
    "opts.num_samples = 2048*3\n",
    "opts.keep_prob = 0.5\n",
    "opts.num_layers = 2\n",
    "opts.learning_rate=0.001\n",
    "\n",
    "model = FBRespective(opts, sess)\n",
    "# model.saver.restore(save_path='ckpt/fb-dskg-hs512_4', sess= sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load file from local\n",
      "start gen filter mat\n",
      "WARNING:tensorflow:From /home/lingbing/Projects/kgcompletion/implementations/DSKG/model.py:379: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n"
     ]
    }
   ],
   "source": [
    "file_name = 'wn-dskg-hs512'\n",
    "\n",
    "opts.hidden_size = 512\n",
    "opts.num_samples = 2048*3\n",
    "opts.keep_prob = 0.5\n",
    "opts.num_layers = 2\n",
    "opts.learning_rate=0.001\n",
    "\n",
    "opts.data_path = 'data/wordnet-mlj12/'\n",
    "\n",
    "model = WNRespective(opts, sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_ranks(probs, method, label):\n",
    "    if method == 'min':\n",
    "        probs = probs - probs[range(len(label)), label].reshape(len(probs), 1)\n",
    "        ranks = (probs > 0).sum(axis=1) + 1\n",
    "    else:\n",
    "        ranks = pd.DataFrame(probs).rank(axis=1, ascending=False, method=method)\n",
    "        ranks = ranks.values[range(len(label)), label]\n",
    "    return ranks\n",
    "\n",
    "def cal_performance(ranks, top=10):\n",
    "    m_r = sum(ranks) * 1.0 / len(ranks)\n",
    "    h_10 = sum(ranks <= top) * 1.0 / len(ranks)\n",
    "    mrr = (1. / ranks).sum() / len(ranks)\n",
    "    return m_r, h_10, mrr\n",
    "\n",
    "def eval_entity_prediction(model, data, filter_mat, method='min', return_ranks=False, return_probs=False, return_label_probs=False):\n",
    "    options = model._options\n",
    "    batch_size = options.batch_size\n",
    "    \n",
    "    label = data[:, 2]\n",
    "    \n",
    "    data, padding_num = model.padding_data(data)\n",
    "\n",
    "    num_batch = len(data) // batch_size \n",
    "    \n",
    "    e_placeholder, r_placeholder, fectch_entity_probs = model._eval_e, model._eval_r, model._entity_probs\n",
    "    \n",
    "    probs = []\n",
    "    for i in range(num_batch):\n",
    "        e = data[:, 0][i * batch_size:(i + 1) * batch_size]\n",
    "        r = data[:, 1][i * batch_size:(i + 1) * batch_size]\n",
    "        \n",
    "        feed_dict = {}\n",
    "        feed_dict[e_placeholder] = e\n",
    "        feed_dict[r_placeholder] = r\n",
    "        \n",
    "        probs.append(sess.run(fectch_entity_probs, feed_dict))\n",
    "    probs = np.concatenate(probs)[:len(data) - padding_num]\n",
    "\n",
    "    if return_label_probs:\n",
    "        return probs[range(len(label)), label]\n",
    "    \n",
    "    if return_probs:\n",
    "        return probs\n",
    "\n",
    "    filter_probs = probs * filter_mat\n",
    "    filter_probs[range(len(label)), label] = probs[range(len(label)), label]\n",
    "\n",
    "    filter_ranks = cal_ranks(filter_probs, method=method, label=label)\n",
    "    if return_ranks:\n",
    "        return filter_ranks\n",
    "    ranks = cal_ranks(probs, method=method, label=label)\n",
    "    m_r, h_10, mrr = cal_performance(ranks)\n",
    "    f_m_r, f_h_10, f_mrr = cal_performance(filter_ranks)\n",
    "    \n",
    "    return (m_r, h_10, mrr, f_m_r, f_h_10, f_mrr)\n",
    "\n",
    "def eval_relation_prediction(model, data, filter_mat, method='min', return_ranks=False, return_probs=False):\n",
    "    options = model._options\n",
    "    batch_size = options.batch_size\n",
    "    \n",
    "    #data[:, 0]-->e, data[:, 1]-->r, data[:, 2]-->e2\n",
    "    label = data[:, 1]\n",
    "    \n",
    "    data, padding_num = model.padding_data(data)\n",
    "\n",
    "    num_batch = len(data) // batch_size\n",
    "    \n",
    "    e_placeholder, fectch_relation_probs = model._eval_e, model._relation_probs\n",
    "    \n",
    "    probs = []\n",
    "    \n",
    "    for i in range(num_batch):\n",
    "        e = data[:, 0][i * batch_size:(i + 1) * batch_size]\n",
    "        \n",
    "        feed_dict = {}\n",
    "        feed_dict[e_placeholder] = e\n",
    "        \n",
    "        probs.append(sess.run(fectch_relation_probs, feed_dict))\n",
    "        \n",
    "    probs = np.concatenate(probs)[:len(data) - padding_num]\n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.array(model._test_data[['h_id', 'r_id', 't_id']].values)\n",
    "train_data = model._train_data[['h_id', 'r_id', 't_id']].values\n",
    "valid_data = model._valid_data[['h_id', 'r_id', 't_id']].values\n",
    "filter_mat = model._tail_test_filter_mat\n",
    "vfilter_mat = model._tail_valid_filter_mat\n",
    "\n",
    "all_data = np.concatenate([train_data, test_data,valid_data])\n",
    "p_data = np.concatenate([test_data,valid_data])\n",
    "\n",
    "def gen_rev_rel(test_data):\n",
    "    half = len(test_data)//2\n",
    "    forward = test_data[:half]\n",
    "    back = test_data[half:]\n",
    "    rev_rel_test_data = test_data[:]\n",
    "    rev_rel = np.concatenate([back[:,1], forward[:,1]])\n",
    "    return rev_rel\n",
    "\n",
    "rev_rel = gen_rev_rel(test_data)\n",
    "vrev_rel=  gen_rev_rel(valid_data)\n",
    "\n",
    "rev_rel_test_data = np.stack([np.arange(model._entity_num),np.arange(model._entity_num)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cal_r(probs, label, filter_mat):\n",
    "    filter_probs = probs * filter_mat\n",
    "    \n",
    "    filter_probs[range(len(label)), label] = probs[range(len(label)), label]\n",
    "    filter_ranks = cal_ranks(filter_probs, method='min', label=label)\n",
    "    \n",
    "    return filter_ranks\n",
    "\n",
    "\n",
    "def joint_eval(test_data, filter_mat, rev_rel):\n",
    "    label=test_data[:, 2]\n",
    "\n",
    "    ep =  eval_entity_prediction(model, data=test_data, filter_mat=filter_mat, return_probs=True)\n",
    "    efr = cal_r(ep, label, filter_mat)\n",
    "    if use_jeval:\n",
    "        rp = eval_relation_prediction(model, rev_rel_test_data, filter_mat=None, return_probs=True).T\n",
    "        rp = rp**0.33\n",
    "        rp = rp[rev_rel]\n",
    "        joint_probs = ep * rp\n",
    "        joint_fr = cal_r(joint_probs, label, filter_mat)\n",
    "    else:\n",
    "        joint_fr = efr\n",
    "    return joint_fr, efr\n",
    "\n",
    "def process_ranks(efr, i=0, last_mean_loss=1000):\n",
    "\n",
    "    MR, H1, MRR = cal_performance(efr[:len(efr)], top=1)\n",
    "    _, H10, _ = cal_performance(efr[:len(efr)], top=10)\n",
    "    msg = 'epoch:%i, Hits@1:%.3f, Hits@10:%.3f, MR:%.3f, MRR:%.3f, mean_loss:%.3f' % (i, H1, H10, MR, MRR, last_mean_loss)\n",
    "    print(msg)\n",
    "    return (i, H1, H10, MR, MRR, last_mean_loss)\n",
    "\n",
    "def handle_eval(i=0, last_mean_loss=1000, valid=True, test=True):\n",
    "    if valid:\n",
    "        jfr, efr = joint_eval(test_data=valid_data, filter_mat=vfilter_mat, rev_rel=vrev_rel)\n",
    "        msg = process_ranks(efr, i, last_mean_loss)\n",
    "        jmsg = process_ranks(jfr, i, last_mean_loss)\n",
    "        valid_results.append(msg)\n",
    "        valid_results.append(jmsg)\n",
    "        if i % 50 == 0:\n",
    "            pd.DataFrame(valid_results, columns=['epoch','Hits@1', 'Hits@10', 'MR', 'MRR', 'mean_loss']).to_csv('results/'+file_name+'valid')\n",
    "        \n",
    "    if test:\n",
    "        jfr, efr = joint_eval(test_data=test_data, filter_mat=filter_mat, rev_rel=rev_rel)\n",
    "        msg = process_ranks(efr, i, last_mean_loss)\n",
    "        jmsg = process_ranks(jfr, i, last_mean_loss)\n",
    "        results.append(msg)\n",
    "        results.append(jmsg)\n",
    "        if i % 50 == 0:\n",
    "            pd.DataFrame(results, columns=['epoch','Hits@1', 'Hits@10', 'MR', 'MRR', 'mean_loss']).to_csv('results/'+file_name+'test')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, Hits@1:0.000, Hits@10:0.000, MR:20291.143, MRR:0.000, mean_loss:0.000\n",
      "epoch:0, Hits@1:0.000, Hits@10:0.000, MR:20254.741, MRR:0.000, mean_loss:0.000\n"
     ]
    }
   ],
   "source": [
    "jfr, efr = joint_eval(test_data=test_data, filter_mat=filter_mat, rev_rel=rev_rel)\n",
    "msg = process_ranks(efr, 0, 0)\n",
    "jmsg = process_ranks(jfr, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch =0\n",
    "results = []\n",
    "valid_results = []\n",
    "last_mean_loss=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the function handle_eval(i=i, last_mean_loss=last_mean_loss, valid=True, test=True) will return 4 results:\n",
    "1. result on valid set\n",
    "2. result on valid set using relation enhancement method\n",
    "1. result on test set\n",
    "2. result on test set using relation enhancement method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, Hits@1:0.000, Hits@10:0.001, MR:20438.791, MRR:0.000, mean_loss:1000.000\n",
      "epoch:0, Hits@1:0.000, Hits@10:0.000, MR:20413.237, MRR:0.000, mean_loss:1000.000\n",
      "epoch:0, Hits@1:0.000, Hits@10:0.000, MR:20291.143, MRR:0.000, mean_loss:1000.000\n",
      "epoch:0, Hits@1:0.000, Hits@10:0.000, MR:20254.741, MRR:0.000, mean_loss:1000.000\n",
      "2048 138 0.001 100000\n",
      "2048 138 0.001 10.6131076813\n",
      "2048 138 0.001 9.15282474048\n",
      "2048 138 0.001 8.14522307507\n",
      "2048 138 0.001 6.97450371756\n",
      "epoch:5, Hits@1:0.010, Hits@10:0.040, MR:4400.382, MRR:0.021, mean_loss:5.690\n",
      "epoch:5, Hits@1:0.011, Hits@10:0.042, MR:4129.618, MRR:0.022, mean_loss:5.690\n",
      "epoch:5, Hits@1:0.009, Hits@10:0.042, MR:4229.783, MRR:0.021, mean_loss:5.690\n",
      "epoch:5, Hits@1:0.009, Hits@10:0.044, MR:3971.097, MRR:0.022, mean_loss:5.690\n",
      "2048 138 0.001 5.68985924168\n",
      "2048 138 0.001 4.47712259362\n",
      "2048 138 0.001 3.59844942197\n",
      "2048 138 0.001 3.0847609786\n",
      "2048 138 0.001 2.80869320337\n",
      "epoch:10, Hits@1:0.329, Hits@10:0.595, MR:456.767, MRR:0.421, mean_loss:2.652\n",
      "epoch:10, Hits@1:0.333, Hits@10:0.600, MR:438.900, MRR:0.425, mean_loss:2.652\n",
      "epoch:10, Hits@1:0.328, Hits@10:0.601, MR:422.927, MRR:0.421, mean_loss:2.652\n",
      "epoch:10, Hits@1:0.330, Hits@10:0.607, MR:404.140, MRR:0.424, mean_loss:2.652\n",
      "2048 138 0.001 2.65226365172\n",
      "2048 138 0.001 2.55633250872\n",
      "2048 138 0.001 2.49302275976\n",
      "2048 138 0.001 2.44698858952\n",
      "63 2.46916\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3728728562bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mhandle_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_mean_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_mean_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlast_mean_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/kgcompletion/implementations/DSKG/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, t_labels, r_labels)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_r\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_batch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_batch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mone_batch_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(epoch, 505):\n",
    "    if i % 5 == 0:\n",
    "        handle_eval(i=i, last_mean_loss=last_mean_loss, valid=True, test=True)\n",
    "    last_mean_loss = model.train()\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
